{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41a4fa21",
   "metadata": {},
   "source": [
    "### **Can execute python codes and plot visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915243b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1160fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import base64\n",
    "\n",
    "@dataclass\n",
    "class RuntimeContext:\n",
    "    df: pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702e508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Fixed execute_code with better variable handling\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.runtime import get_runtime\n",
    "import sys\n",
    "from io import StringIO\n",
    "import inspect\n",
    "\n",
    "@tool\n",
    "def execute_code(code: str) -> str:\n",
    "    \"\"\"Execute Python code blocks including plots, models, and multi-line operations.\n",
    "    \n",
    "    Args:\n",
    "        code: Python code block. Use 'df' for the DataFrame, 'pd' for pandas,\n",
    "              'plt' for matplotlib, 'np' for numpy.\n",
    "    \"\"\"\n",
    "    runtime = get_runtime(RuntimeContext)\n",
    "    df = runtime.context.df\n",
    "    \n",
    "    # Capture stdout\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = captured_output = StringIO()\n",
    "    \n",
    "    # Prepare namespace with common libraries\n",
    "    namespace = {\n",
    "        'df': df,\n",
    "        'pd': pd,\n",
    "        'plt': plt,\n",
    "        'np': __import__('numpy'),\n",
    "    }\n",
    "    \n",
    "    # Try to import optional libraries\n",
    "    try:\n",
    "        import seaborn as sns\n",
    "        namespace['sns'] = sns\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # Execute the code\n",
    "        exec(code, namespace)\n",
    "        \n",
    "        # Get printed output\n",
    "        output = captured_output.getvalue()\n",
    "        \n",
    "        # Check if a plot was created\n",
    "        plot_created = False\n",
    "        if plt.get_fignums():\n",
    "            plot_created = True\n",
    "            buf = io.BytesIO()\n",
    "            plt.savefig(buf, format='png', bbox_inches='tight')\n",
    "            plt.close('all')\n",
    "            buf.seek(0)\n",
    "            img_base64 = base64.b64encode(buf.read()).decode()\n",
    "        \n",
    "        # Collect interesting variables from namespace\n",
    "        result_vars = {}\n",
    "        excluded_names = {'df', 'pd', 'plt', 'np', 'sns'}\n",
    "        \n",
    "        for key, value in namespace.items():\n",
    "            # Skip private variables and excluded names\n",
    "            if key.startswith('_') or key in excluded_names:\n",
    "                continue\n",
    "            \n",
    "            # Skip functions and classes (but keep instances)\n",
    "            if inspect.isfunction(value) or inspect.isclass(value):\n",
    "                continue\n",
    "            \n",
    "            # Skip modules\n",
    "            if inspect.ismodule(value):\n",
    "                continue\n",
    "            \n",
    "            # Include everything else (numbers, strings, sklearn models, numpy arrays, etc.)\n",
    "            try:\n",
    "                # Try to convert to string (some objects can't be stringified)\n",
    "                str_value = str(value)\n",
    "                # Limit length to avoid huge outputs\n",
    "                if len(str_value) > 500:\n",
    "                    str_value = str_value[:500] + \"...\"\n",
    "                result_vars[key] = str_value\n",
    "            except:\n",
    "                result_vars[key] = f\"<{type(value).__name__} object>\"\n",
    "        \n",
    "        # Build output\n",
    "        output_parts = []\n",
    "        \n",
    "        if output:\n",
    "            output_parts.append(f\"Output:\\n{output.strip()}\")\n",
    "        \n",
    "        if result_vars:\n",
    "            vars_str = \"\\n\".join([f\"{k} = {v}\" for k, v in result_vars.items()])\n",
    "            output_parts.append(f\"Variables created:\\n{vars_str}\")\n",
    "        \n",
    "        if plot_created:\n",
    "            output_parts.append(\"[Plot created and displayed]\")\n",
    "        \n",
    "        if output_parts:\n",
    "            return \"\\n\\n\".join(output_parts)\n",
    "        else:\n",
    "            return \"Code executed successfully (no output)\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_details = traceback.format_exc()\n",
    "        return f\"Error: {str(e)}\\n\\nDetails:\\n{error_details}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce3821b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def query_dataframe(pandas_code: str) -> str:\n",
    "    \"\"\"Quick pandas operations (single expressions only).\n",
    "    \n",
    "    Args:\n",
    "        pandas_code: Single pandas expression (e.g., \"df.head()\", \"df.describe()\")\n",
    "    \"\"\"\n",
    "    runtime = get_runtime(RuntimeContext)\n",
    "    df = runtime.context.df\n",
    "\n",
    "    try:\n",
    "        result = eval(pandas_code, {\"df\": df, \"pd\": pd})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "580ea4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a data analyst and data scientist assistant.\n",
    "\n",
    "Tools available:\n",
    "1. query_dataframe: For simple, single-line pandas operations\n",
    "   - Use for: df.head(), df.describe(), df.shape, etc.\n",
    "\n",
    "2. execute_code: For complex operations, visualizations, and models\n",
    "   - Use for: plots, multi-line code, model training, data transformations\n",
    "   - Available imports: pd (pandas), plt (matplotlib), np (numpy)\n",
    "   - The DataFrame is available as 'df'\n",
    "\n",
    "Rules:\n",
    "- For simple queries, use query_dataframe\n",
    "- For plots or complex analysis, use execute_code\n",
    "- When creating plots, use plt.figure(), create the plot, then plt.show()\n",
    "- **IMPORTANT: Always use print() to display results like metrics, scores, statistics**\n",
    "- When calculating metrics (precision, recall, accuracy, etc.), ALWAYS print them\n",
    "- If code fails, debug and try again\n",
    "\n",
    "Examples:\n",
    "- Simple: query_dataframe(\"df.shape\")\n",
    "- Plot: execute_code(\"plt.figure()\\\\nplt.hist(df['Age'])\\\\nplt.title('Age Distribution')\\\\nplt.show()\")\n",
    "- Metrics: execute_code(\"from sklearn.metrics import accuracy_score\\\\nacc = accuracy_score(y_test, y_pred)\\\\nprint(f'Accuracy: {acc}')\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e69e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[query_dataframe, execute_code],  # Both tools available\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    context_schema=RuntimeContext,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36d3a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Plot display helper\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def run_with_plots(question: str, thread_id: str = \"1\"):\n",
    "    \"\"\"Run agent and display any plots created.\"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    for step in agent.stream(\n",
    "        {\"messages\": question},\n",
    "        context=RuntimeContext(df=df),\n",
    "        config=config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        last_msg = step[\"messages\"][-1]\n",
    "        last_msg.pretty_print()\n",
    "        \n",
    "        # Check if this was a tool response with a plot\n",
    "        if hasattr(last_msg, 'content') and '[Plot saved' in str(last_msg.content):\n",
    "            # The plot was created, matplotlib should show it\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84849f89",
   "metadata": {},
   "source": [
    "#### Test 1: Simple query\n",
    "run_with_plots(\"What's the average age?\", \"test1\")\n",
    "\n",
    "#### Test 2: Visualization\n",
    "run_with_plots(\"Show me a bar chart of survival by passenger class\", \"test2\")\n",
    "\n",
    "#### Test 3: Statistical analysis\n",
    "run_with_plots(\"Calculate correlation between Age and Fare, show as heatmap\", \"test3\")\n",
    "\n",
    "#### Test 4: Machine learning\n",
    "run_with_plots(\"Train a decision tree to predict survival and show feature importance\", \"test4\")\n",
    "\n",
    "#### Test 5: Complex transformation\n",
    "run_with_plots(\"\"\"\n",
    "Create a new feature 'FamilySize' (SibSp + Parch + 1).\n",
    "Then create a violin plot showing Fare distribution by FamilySize.\n",
    "\"\"\", \"test5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c05b08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Apply the necessary preprocessing steps on the data. Then train a logistic regression model on this dataset. Then, give me the precision and recall scores of the trained model.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To start, I will first analyze the dataset to determine the necessary preprocessing steps. This may include handling missing values, encoding categorical variables, and normalizing or scaling the data if needed. \n",
      "\n",
      "Let's first take a look at the dataset to understand its structure and any preprocessing requirements. I will start with checking the first few rows and the data types. \n",
      "\n",
      "Let's proceed with that.\n",
      "Tool Calls:\n",
      "  query_dataframe (call_yhqD4zA52tf7sTJ74r5CUuJ1)\n",
      " Call ID: call_yhqD4zA52tf7sTJ74r5CUuJ1\n",
      "  Args:\n",
      "    pandas_code: df.head()\n",
      "  query_dataframe (call_PcUbgIDjUNdnCPKTT4KjUuQ8)\n",
      " Call ID: call_PcUbgIDjUNdnCPKTT4KjUuQ8\n",
      "  Args:\n",
      "    pandas_code: df.info()\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: query_dataframe\n",
      "\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The dataset consists of the following columns:\n",
      "\n",
      "- **PassengerId**: An identifier for the passengers.\n",
      "- **Survived**: The target variable (1 if survived, 0 otherwise).\n",
      "- **Pclass**: Passenger class (1, 2, or 3).\n",
      "- **Name**: Passenger names.\n",
      "- **Sex**: Gender of the passenger.\n",
      "- **Age**: Age of the passenger (some values are likely missing).\n",
      "- **SibSp**: Number of siblings/spouses aboard.\n",
      "- **Parch**: Number of parents/children aboard.\n",
      "- **Ticket**: Ticket number.\n",
      "- **Fare**: Fare paid for the ticket.\n",
      "- **Cabin**: Cabin number (many values might be missing).\n",
      "- **Embarked**: Port of embarkation (C, Q, S).\n",
      "\n",
      "### Preprocessing Steps Needed\n",
      "1. **Handle Missing Values**:\n",
      "   - Age: Fill missing values with the median or mean.\n",
      "   - Cabin: Can be dropped as it has many missing values.\n",
      "   - Embarked: Fill missing values with the mode.\n",
      "   \n",
      "2. **Encode Categorical Variables**:\n",
      "   - Convert \"Sex\" and \"Embarked\" into numerical values.\n",
      "   \n",
      "3. **Feature Selection**:\n",
      "   - Drop non-informative features such as \"PassengerId\", \"Name\", \"Ticket\", and \"Cabin\".\n",
      "   \n",
      "4. **Scale Numerical Features**:\n",
      "   - Scale the \"Fare\" feature and possibly \"Age\" for logistic regression.\n",
      "\n",
      "Now, I'll implement these preprocessing steps and then train a logistic regression model on the processed dataset. Let's proceed with that.\n",
      "Tool Calls:\n",
      "  execute_code (call_CIMV47JpcwSVIdhr8KZ8TKn6)\n",
      " Call ID: call_CIMV47JpcwSVIdhr8KZ8TKn6\n",
      "  Args:\n",
      "    code: # Import necessary libraries\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import precision_score, recall_score\n",
      "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
      "\n",
      "# Step 1: Handle missing values\n",
      "# Filling missing Age values with the median\n",
      "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
      "# Filling missing Embarked values with the mode\n",
      "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
      "# Drop Cabin as it has too many missing values\n",
      "\n",
      "# Step 2: Encode categorical variables\n",
      "le = LabelEncoder()\n",
      "# Encoding 'Sex'\n",
      "df['Sex'] = le.fit_transform(df['Sex'])  # male = 1, female = 0\n",
      "# Encoding 'Embarked'\n",
      "df['Embarked'] = le.fit_transform(df['Embarked'])  # C, Q, S will be encoded\n",
      "\n",
      "# Step 3: Feature selection\n",
      "features = df.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
      "labels = df['Survived']\n",
      "\n",
      "# Step 4: Scale numerical features\n",
      "scaler = StandardScaler()\n",
      "features[['Age', 'Fare']] = scaler.fit_transform(features[['Age', 'Fare']])\n",
      "\n",
      "# Split data into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
      "\n",
      "# Train logistic regression model\n",
      "model = LogisticRegression()\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Make predictions\n",
      "y_pred = model.predict(X_test)\n",
      "\n",
      "# Calculate precision and recall\n",
      "precision = precision_score(y_test, y_pred)\n",
      "recall = recall_score(y_test, y_pred)\n",
      "print(f'Precision: {precision}')\n",
      "print(f'Recall: {recall}')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: execute_code\n",
      "\n",
      "Output:\n",
      "Precision: 0.7857142857142857\n",
      "Recall: 0.7432432432432432\n",
      "\n",
      "Variables created:\n",
      "le = LabelEncoder()\n",
      "features =      Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
      "0         3    1 -0.565736      1      0 -0.502445         2\n",
      "1         1    0  0.663861      1      0  0.786845         0\n",
      "2         3    0 -0.258337      0      0 -0.488854         2\n",
      "3         1    0  0.433312      1      0  0.420730         2\n",
      "4         3    1  0.433312      0      0 -0.486337         2\n",
      "..      ...  ...       ...    ...    ...       ...       ...\n",
      "886       2    1 -0.181487      0      0 -0.386671         2\n",
      "887       1 ...\n",
      "labels = 0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "886    0\n",
      "887    1\n",
      "888    0\n",
      "889    1\n",
      "890    0\n",
      "Name: Survived, Length: 891, dtype: int64\n",
      "scaler = StandardScaler()\n",
      "X_train =      Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
      "331       1    1  1.240235      0      0 -0.074583         2\n",
      "733       2    1 -0.488887      0      0 -0.386671         2\n",
      "382       3    1  0.202762      0      0 -0.488854         2\n",
      "704       3    1 -0.258337      1      0 -0.490280         2\n",
      "813       3    0 -1.795334      4      2 -0.018709         2\n",
      "..      ...  ...       ...    ...    ...       ...       ...\n",
      "106       3    0 -0.642586      0      0 -0.494391         2\n",
      "270       1 ...\n",
      "X_test =      Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
      "709       3    1 -0.104637      1      1 -0.341452         0\n",
      "439       2    1  0.125912      0      0 -0.437007         2\n",
      "840       3    1 -0.719436      0      0 -0.488854         2\n",
      "720       2    0 -1.795334      0      1  0.016023         2\n",
      "39        3    0 -1.180535      1      0 -0.422074         0\n",
      "..      ...  ...       ...    ...    ...       ...       ...\n",
      "433       3    1 -0.949986      0      0 -0.504962         2\n",
      "773       3 ...\n",
      "y_train = 331    0\n",
      "733    0\n",
      "382    0\n",
      "704    0\n",
      "813    0\n",
      "      ..\n",
      "106    1\n",
      "270    0\n",
      "860    0\n",
      "435    1\n",
      "102    0\n",
      "Name: Survived, Length: 712, dtype: int64\n",
      "y_test = 709    1\n",
      "439    0\n",
      "840    0\n",
      "720    1\n",
      "39     1\n",
      "      ..\n",
      "433    0\n",
      "773    0\n",
      "25     1\n",
      "84     1\n",
      "10     1\n",
      "Name: Survived, Length: 179, dtype: int64\n",
      "model = LogisticRegression()\n",
      "y_pred = [0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0\n",
      " 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1\n",
      " 0 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1]\n",
      "precision = 0.7857142857142857\n",
      "recall = 0.7432432432432432\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The preprocessing steps have been successfully completed, and a logistic regression model has been trained on the dataset. \n",
      "\n",
      "### Model Evaluation Metrics\n",
      "- **Precision**: 0.7857\n",
      "- **Recall**: 0.7432\n",
      "\n",
      "These values indicate that the model is reasonably effective at identifying the positive class (survived). If you need any further analysis or actions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "run_with_plots(\"Apply the necessary preprocessing steps on the data. Then train a logistic regression model on this dataset. Then, give me the precision and recall scores of the trained model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain Essentials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
