{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# HYBRID CSV INTELLIGENCE SYSTEM - LANGCHAIN COMPATIBLE\n",
    "# Using LangChain Agents + Custom Tools + Groq LLM\n",
    "# ============================================================\n",
    "\n",
    "# STEP 1: Install Required Libraries\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# STEP 2: Import Libraries\n",
    "# ============================================================\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "from google.colab import files\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# STEP 3: Global Variables\n",
    "# ============================================================\n",
    "df = None\n",
    "collection = None\n",
    "embedding_model = None\n",
    "llm = None\n",
    "chroma_client = None\n",
    "conversation_history = []\n",
    "DEBUG_MODE = True\n",
    "\n",
    "# STEP 4: Initialize System\n",
    "# ============================================================\n",
    "\n",
    "def initialize_system(api_key: str):\n",
    "    \"\"\"Initialize LangChain with Groq LLM\"\"\"\n",
    "    global embedding_model, llm, chroma_client\n",
    "    \n",
    "    print(\"üîß Initializing LangChain system...\")\n",
    "    \n",
    "    # Initialize Groq LLM\n",
    "    llm = ChatGroq(\n",
    "        api_key=api_key,\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        temperature=0.1,\n",
    "        max_tokens=2000\n",
    "    )\n",
    "    print(\"‚úì Groq LLM (Llama 3.3 70B) initialized\")\n",
    "    \n",
    "    # Load embedding model\n",
    "    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    print(\"‚úì Embedding model loaded\")\n",
    "    \n",
    "    # Initialize ChromaDB\n",
    "    chroma_client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
    "    print(\"‚úì Vector database ready\")\n",
    "    \n",
    "    print(\"‚úÖ LangChain system initialized!\\n\")\n",
    "\n",
    "# STEP 5: Vector Database Functions (RAG)\n",
    "# ============================================================\n",
    "\n",
    "def create_vector_db(dataframe: pd.DataFrame):\n",
    "    \"\"\"Create vector database from CSV\"\"\"\n",
    "    global collection\n",
    "    \n",
    "    try:\n",
    "        chroma_client.delete_collection(name=\"csv_data\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    collection = chroma_client.create_collection(\n",
    "        name=\"csv_data\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "    \n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "    \n",
    "    for idx, row in dataframe.iterrows():\n",
    "        doc_text = \" | \".join([f\"{col}: {row[col]}\" for col in dataframe.columns])\n",
    "        documents.append(doc_text)\n",
    "        metadatas.append({\"row_index\": idx})\n",
    "        ids.append(f\"row_{idx}\")\n",
    "    \n",
    "    print(f\"üìä Creating vector embeddings for {len(documents)} rows...\")\n",
    "    embeddings = embedding_model.encode(documents, show_progress_bar=False).tolist()\n",
    "    \n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        embeddings=embeddings,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úì Vector database created\\n\")\n",
    "\n",
    "def semantic_search(query: str, top_k: int = 5) -> str:\n",
    "    \"\"\"Perform semantic search and return results\"\"\"\n",
    "    if collection is None:\n",
    "        return \"No data indexed yet\"\n",
    "    \n",
    "    if DEBUG_MODE:\n",
    "        print(f\"\\nüîç [RAG] Searching for: {query}\")\n",
    "    \n",
    "    query_embedding = embedding_model.encode([query])[0].tolist()\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    output = []\n",
    "    for i in range(len(results['ids'][0])):\n",
    "        row_idx = results['metadatas'][0][i]['row_index']\n",
    "        doc = results['documents'][0][i]\n",
    "        output.append(f\"Row {row_idx}: {doc}\")\n",
    "    \n",
    "    result = \"\\n\".join(output)\n",
    "    \n",
    "    if DEBUG_MODE:\n",
    "        print(f\"‚úì Found {len(output)} relevant rows\\n\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# STEP 6: Custom Tool Functions\n",
    "# ============================================================\n",
    "\n",
    "def get_csv_info() -> str:\n",
    "    \"\"\"Get CSV dataset information\"\"\"\n",
    "    if df is None:\n",
    "        return \"No CSV loaded\"\n",
    "    \n",
    "    info = f\"\"\"Dataset Information:\n",
    "- Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\n",
    "- Columns: {', '.join(df.columns.tolist())}\n",
    "- Data Types: {df.dtypes.to_dict()}\n",
    "\n",
    "First 3 rows:\n",
    "{df.head(3).to_string()}\n",
    "\n",
    "Basic Statistics:\n",
    "{df.describe().to_string()}\n",
    "\"\"\"\n",
    "    return info\n",
    "\n",
    "def execute_pandas_query(query: str) -> str:\n",
    "    \"\"\"Execute pandas operations using LangChain agent\"\"\"\n",
    "    if df is None:\n",
    "        return \"No CSV loaded\"\n",
    "    \n",
    "    if DEBUG_MODE:\n",
    "        print(f\"\\nüêç [Pandas Agent] Processing: {query}\")\n",
    "    \n",
    "    try:\n",
    "        pandas_agent = create_pandas_dataframe_agent(\n",
    "            llm,\n",
    "            df,\n",
    "            verbose=DEBUG_MODE,\n",
    "            agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            allow_dangerous_code=True,\n",
    "            max_iterations=5,\n",
    "            handle_parsing_errors=True\n",
    "        )\n",
    "        \n",
    "        result = pandas_agent.invoke(query)\n",
    "        \n",
    "        if DEBUG_MODE:\n",
    "            print(f\"‚úì Pandas operation completed\\n\")\n",
    "        \n",
    "        if isinstance(result, dict):\n",
    "            return str(result.get('output', result))\n",
    "        return str(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error in pandas operation: {str(e)}\"\n",
    "\n",
    "def create_visualization(query: str) -> str:\n",
    "    \"\"\"Create visualizations from data\"\"\"\n",
    "    if df is None:\n",
    "        return \"No CSV loaded\"\n",
    "    \n",
    "    if DEBUG_MODE:\n",
    "        print(f\"\\nüìä [Visualization] Creating: {query}\")\n",
    "    \n",
    "    try:\n",
    "        prompt = f\"\"\"Given this query: \"{query}\"\n",
    "\n",
    "Available columns: {df.columns.tolist()}\n",
    "Sample data: {df.head(2).to_dict()}\n",
    "\n",
    "Generate Python code using plotly express to create the visualization.\n",
    "Use variable 'df' for the dataframe and 'fig' for the plotly figure.\n",
    "Code must use: import plotly.express as px\n",
    "Then: fig = px.[chart_type]()\n",
    "Then: fig.show()\n",
    "\n",
    "Only return the Python code, nothing else.\"\"\"\n",
    "\n",
    "        code_response = llm.invoke(prompt)\n",
    "        code = code_response.content\n",
    "        \n",
    "        # Clean the code\n",
    "        if \"```python\" in code:\n",
    "            code = code.split(\"```python\")[1].split(\"```\")[0]\n",
    "        elif \"```\" in code:\n",
    "            code = code.split(\"```\")[1].split(\"```\")[0]\n",
    "        \n",
    "        code = code.strip()\n",
    "        \n",
    "        if DEBUG_MODE:\n",
    "            print(f\"Generated code:\\n{code}\\n\")\n",
    "        \n",
    "        # Execute the visualization code\n",
    "        exec_globals = {'df': df, 'px': px, 'plt': plt, 'np': np}\n",
    "        exec(code, exec_globals)\n",
    "        \n",
    "        return f\"Visualization created successfully!\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error creating visualization: {str(e)}\"\n",
    "\n",
    "def statistical_analysis(query: str) -> str:\n",
    "    \"\"\"Perform statistical analysis\"\"\"\n",
    "    if df is None:\n",
    "        return \"No CSV loaded\"\n",
    "    \n",
    "    if DEBUG_MODE:\n",
    "        print(f\"\\nüìà [Statistical Analysis] Analyzing: {query}\")\n",
    "    \n",
    "    try:\n",
    "        pandas_agent = create_pandas_dataframe_agent(\n",
    "            llm,\n",
    "            df,\n",
    "            verbose=DEBUG_MODE,\n",
    "            agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            allow_dangerous_code=True,\n",
    "            prefix=\"You are a data scientist. Perform statistical analysis on the dataframe.\"\n",
    "        )\n",
    "        \n",
    "        result = pandas_agent.invoke(f\"Perform statistical analysis: {query}\")\n",
    "        \n",
    "        if isinstance(result, dict):\n",
    "            return str(result.get('output', result))\n",
    "        return str(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error in statistical analysis: {str(e)}\"\n",
    "\n",
    "# STEP 7: Smart Query Router (Agent-like Logic)\n",
    "# ============================================================\n",
    "\n",
    "def route_query(user_query: str) -> Dict[str, Any]:\n",
    "    \"\"\"Route query to appropriate tool\"\"\"\n",
    "    \n",
    "    if DEBUG_MODE:\n",
    "        print(\"\\n\" + \"üéØ \" + \"=\"*60)\n",
    "        print(\"QUERY ROUTING\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"User Query: {user_query}\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    # Build decision prompt\n",
    "    decision_prompt = f\"\"\"You are a query router. Analyze the user's question and decide which tool to use.\n",
    "\n",
    "User Query: \"{user_query}\"\n",
    "\n",
    "CSV Info:\n",
    "- Columns: {df.columns.tolist() if df is not None else 'N/A'}\n",
    "- Shape: {df.shape if df is not None else 'N/A'}\n",
    "\n",
    "Available Tools:\n",
    "1. csv_info - Dataset information (shape, columns, types, sample data)\n",
    "2. semantic_search - Find specific rows using natural language search\n",
    "3. pandas_query - Calculations, counting, filtering, aggregations, grouping\n",
    "4. visualization - Create charts and graphs\n",
    "5. statistical_analysis - Correlations, distributions, statistical tests\n",
    "\n",
    "Respond ONLY with a JSON object:\n",
    "{{\n",
    "    \"tool\": \"tool_name\",\n",
    "    \"reasoning\": \"why this tool\",\n",
    "    \"search_query\": \"refined query for the tool\"\n",
    "}}\n",
    "\n",
    "Guidelines:\n",
    "- Use csv_info for: \"shape\", \"columns\", \"info\", \"dataset information\"\n",
    "- Use semantic_search for: \"find\", \"show me\", \"rows with\", \"passengers named\"\n",
    "- Use pandas_query for: \"count\", \"how many\", \"average\", \"sum\", \"filter\", \"group by\"\n",
    "- Use visualization for: \"chart\", \"plot\", \"graph\", \"visualize\"\n",
    "- Use statistical_analysis for: \"correlation\", \"distribution\", \"outliers\", \"statistics\"\n",
    "\n",
    "Respond ONLY with valid JSON, no markdown.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = llm.invoke(decision_prompt)\n",
    "        decision_text = response.content\n",
    "        \n",
    "        # Extract JSON\n",
    "        import re\n",
    "        json_match = re.search(r'\\{.*\\}', decision_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            decision_text = json_match.group()\n",
    "        \n",
    "        decision = json.loads(decision_text)\n",
    "        \n",
    "        if DEBUG_MODE:\n",
    "            print(f\"\\n‚úÖ ROUTING DECISION\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"Tool: {decision.get('tool', 'N/A')}\")\n",
    "            print(f\"Reasoning: {decision.get('reasoning', 'N/A')}\")\n",
    "            print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        return decision\n",
    "        \n",
    "    except Exception as e:\n",
    "        if DEBUG_MODE:\n",
    "            print(f\"\\n‚ö†Ô∏è Routing failed, defaulting to pandas_query: {str(e)}\\n\")\n",
    "        return {\"tool\": \"pandas_query\", \"search_query\": user_query}\n",
    "\n",
    "def execute_tool(tool_name: str, query: str) -> str:\n",
    "    \"\"\"Execute the selected tool\"\"\"\n",
    "    \n",
    "    tool_map = {\n",
    "        \"csv_info\": get_csv_info,\n",
    "        \"semantic_search\": semantic_search,\n",
    "        \"pandas_query\": execute_pandas_query,\n",
    "        \"visualization\": create_visualization,\n",
    "        \"statistical_analysis\": statistical_analysis\n",
    "    }\n",
    "    \n",
    "    tool_func = tool_map.get(tool_name)\n",
    "    \n",
    "    if tool_func:\n",
    "        if tool_name == \"csv_info\":\n",
    "            return tool_func()\n",
    "        else:\n",
    "            return tool_func(query)\n",
    "    else:\n",
    "        return f\"Unknown tool: {tool_name}\"\n",
    "\n",
    "def process_query(user_query: str) -> str:\n",
    "    \"\"\"Main query processing function\"\"\"\n",
    "    global conversation_history\n",
    "    \n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
    "    \n",
    "    # Route query to appropriate tool\n",
    "    decision = route_query(user_query)\n",
    "    tool_name = decision.get(\"tool\", \"pandas_query\")\n",
    "    search_query = decision.get(\"search_query\", user_query)\n",
    "    \n",
    "    # Execute tool\n",
    "    tool_result = execute_tool(tool_name, search_query)\n",
    "    \n",
    "    # Generate natural language response\n",
    "    if DEBUG_MODE:\n",
    "        print(\"üí¨ Generating final answer...\")\n",
    "    \n",
    "    history_context = \"\\n\".join([\n",
    "        f\"{msg['role'].upper()}: {msg['content']}\" \n",
    "        for msg in conversation_history[-5:]\n",
    "    ])\n",
    "    \n",
    "    final_prompt = f\"\"\"Based on the tool output, provide a clear, concise answer to the user's question.\n",
    "\n",
    "User Question: {user_query}\n",
    "Tool Used: {tool_name}\n",
    "Tool Output:\n",
    "{tool_result}\n",
    "\n",
    "Conversation History:\n",
    "{history_context}\n",
    "\n",
    "Provide a natural language answer. Be specific and clear.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = llm.invoke(final_prompt)\n",
    "        answer = response.content\n",
    "    except Exception as e:\n",
    "        answer = f\"Tool Result: {tool_result}\"\n",
    "    \n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# STEP 8: CSV Management\n",
    "# ============================================================\n",
    "\n",
    "def load_csv_file(file_path: str = None):\n",
    "    \"\"\"Load CSV and create vector database\"\"\"\n",
    "    global df\n",
    "    \n",
    "    if file_path is None:\n",
    "        print(\"üìÅ Please upload your CSV file:\")\n",
    "        uploaded = files.upload()\n",
    "        file_path = list(uploaded.keys())[0]\n",
    "    \n",
    "    print(f\"\\nüìÇ Loading: {file_path}\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    print(f\"‚úì Loaded {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"‚úì Columns: {', '.join(df.columns)}\\n\")\n",
    "    \n",
    "    create_vector_db(df)\n",
    "    \n",
    "    print(\"‚úÖ CSV loaded and ready!\\n\")\n",
    "    return df\n",
    "\n",
    "def show_csv_info():\n",
    "    \"\"\"Display CSV information\"\"\"\n",
    "    if df is None:\n",
    "        print(\"‚ùå No CSV loaded.\\n\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä CSV INFORMATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(get_csv_info())\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# STEP 9: CLI Interface\n",
    "# ============================================================\n",
    "\n",
    "def print_welcome():\n",
    "    \"\"\"Print welcome message\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ü§ñ LANGCHAIN CSV INTELLIGENCE SYSTEM\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"LangChain Tools + Groq (Llama 3.3 70B) + RAG\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nüìã COMMANDS:\")\n",
    "    print(\"  load     - Upload CSV file\")\n",
    "    print(\"  info     - Show CSV info\")\n",
    "    print(\"  tools    - List available tools\")\n",
    "    print(\"  debug    - Toggle debug mode\")\n",
    "    print(\"  clear    - Clear conversation\")\n",
    "    print(\"  quit     - Exit\")\n",
    "    print(\"\\nüí¨ Ask questions about your data!\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "def show_tools():\n",
    "    \"\"\"Show available tools\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üõ†Ô∏è  AVAILABLE TOOLS\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n1. üìä csv_info - Dataset information\")\n",
    "    print(\"2. üîç semantic_search - Find rows by natural language\")\n",
    "    print(\"3. üêç pandas_query - Calculations & aggregations\")\n",
    "    print(\"4. üìà visualization - Create charts\")\n",
    "    print(\"5. üìâ statistical_analysis - Statistical insights\")\n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "def start_chatbot():\n",
    "    \"\"\"Start the CLI chatbot\"\"\"\n",
    "    print_welcome()\n",
    "    \n",
    "    if df is None:\n",
    "        print(\"‚ö†Ô∏è  No CSV loaded.\\n\")\n",
    "        load_response = input(\"Load CSV now? (yes/no): \").strip().lower()\n",
    "        if load_response in ['yes', 'y']:\n",
    "            load_csv_file()\n",
    "    \n",
    "    print(\"üü¢ System ready!\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"You: \").strip()\n",
    "            \n",
    "            if not user_input:\n",
    "                continue\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"\\nüëã Goodbye!\\n\")\n",
    "                break\n",
    "            \n",
    "            elif user_input.lower() == 'load':\n",
    "                load_csv_file()\n",
    "                continue\n",
    "            \n",
    "            elif user_input.lower() == 'info':\n",
    "                show_csv_info()\n",
    "                continue\n",
    "            \n",
    "            elif user_input.lower() == 'tools':\n",
    "                show_tools()\n",
    "                continue\n",
    "            \n",
    "            elif user_input.lower() in ['clear', 'reset']:\n",
    "                conversation_history.clear()\n",
    "                print(\"‚úì Conversation cleared\\n\")\n",
    "                continue\n",
    "            \n",
    "            elif user_input.lower() == 'debug':\n",
    "                global DEBUG_MODE\n",
    "                DEBUG_MODE = not DEBUG_MODE\n",
    "                print(f\"\\nüîß Debug mode: {'ON' if DEBUG_MODE else 'OFF'}\\n\")\n",
    "                continue\n",
    "            \n",
    "            elif user_input.lower() in ['help', '?']:\n",
    "                print_welcome()\n",
    "                continue\n",
    "            \n",
    "            if df is None:\n",
    "                print(\"‚ùå Please load a CSV first\\n\")\n",
    "                continue\n",
    "            \n",
    "            print(\"\\nü§î Processing...\\n\")\n",
    "            \n",
    "            try:\n",
    "                answer = process_query(user_input)\n",
    "                print(f\"\\nü§ñ Assistant: {answer}\\n\")\n",
    "                print(\"-\" * 70 + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ùå Error: {str(e)}\\n\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nüëã Interrupted.\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {str(e)}\\n\")\n",
    "\n",
    "# STEP 10: Main\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üöÄ LANGCHAIN CSV INTELLIGENCE SYSTEM\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    print(\"üîë Get FREE API key: https://console.groq.com/keys\")\n",
    "    api_key = input(\"Enter Groq API Key: \").strip()\n",
    "    \n",
    "    if not api_key:\n",
    "        print(\"\\n‚ùå API key required!\\n\")\n",
    "        return\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        initialize_system(api_key)\n",
    "        start_chatbot()\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {str(e)}\\n\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
